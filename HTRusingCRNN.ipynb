{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxwrLrZB8y9Z",
        "outputId": "e351806b-1022-443a-897c-ed8dc57f2f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lmdb\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/299.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lmdb\n",
            "Successfully installed lmdb-1.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install lmdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZjP6wr885PC",
        "outputId": "ca4b6d5d-a4d4-42d8-9268-bb3c973581b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting path\n",
            "  Downloading path-16.7.1-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: path\n",
            "Successfully installed path-16.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUDpqEFZ8dGa"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import json\n",
        "import random\n",
        "from collections import namedtuple\n",
        "from typing import Tuple, List\n",
        "import editdistance\n",
        "import tensorflow as tf\n",
        "import argparse\n",
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "import lmdb\n",
        "import numpy as np\n",
        "from path import Path\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "7FkEAClNAfiZ",
        "outputId": "60c676d4-f0d0-4df1-9cff-263e8b176773"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-91cd795a-2839-4b14-8655-89509ad2c81f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-91cd795a-2839-4b14-8655-89509ad2c81f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving words.tgz to words.tgz\n",
            "Archive:  words.tgz\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of words.tgz or\n",
            "        words.tgz.zip, and cannot find words.tgz.ZIP, period.\n"
          ]
        }
      ],
      "source": [
        "uploaded = files.upload()\n",
        "zip_filename = list(uploaded.keys())[0]\n",
        "!unzip $zip_filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TNjdX4LAsoH"
      },
      "outputs": [],
      "source": [
        "data_dir = Path(\"/content/words.tgz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKoXzMzIA2sR"
      },
      "outputs": [],
      "source": [
        "assert not (data_dir / 'lmdb').exists()\n",
        "env = lmdb.open(str(data_dir / 'lmdb'), map_size=1024 * 1024 * 1024 * 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0te9Y9FA7lX"
      },
      "outputs": [],
      "source": [
        "fn_imgs = list((data_dir / 'img').walkfiles('*.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beUc1FjDA8Gq"
      },
      "outputs": [],
      "source": [
        "with env.begin(write=True) as txn:\n",
        "    for i, fn_img in enumerate(fn_imgs):\n",
        "        print(i, len(fn_imgs))\n",
        "        img = cv2.imread(fn_img, cv2.IMREAD_GRAYSCALE)\n",
        "        basename = fn_img.basename()\n",
        "        txn.put(basename.encode(\"ascii\"), pickle.dumps(img))\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oo_q38eA8nMt"
      },
      "outputs": [],
      "source": [
        "Sample = namedtuple('Sample', 'gt_text, file_path')\n",
        "Batch = namedtuple('Batch', 'imgs, gt_texts, batch_size')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjrZ2EDO9AJY"
      },
      "outputs": [],
      "source": [
        "class DataLoaderIAM:\n",
        "    def __init__(self,\n",
        "                 data_dir: Path,\n",
        "                 batch_size: int,\n",
        "                 data_split: float = 0.95,\n",
        "                 fast: bool = True) -> None:\n",
        "        assert data_dir.exists()\n",
        "        self.fast = fast\n",
        "        if fast:\n",
        "            self.env = lmdb.open(str(data_dir / 'lmdb'), readonly=True)\n",
        "        self.data_augmentation = False\n",
        "        self.curr_idx = 0\n",
        "        self.batch_size = batch_size\n",
        "        self.samples = []\n",
        "        f = open(data_dir / 'gt/words.txt')\n",
        "        chars = set()\n",
        "        bad_samples_reference = ['a01-117-05-02', 'r06-022-03-05']\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line or line[0] == '#':\n",
        "                continue\n",
        "            line_split = line.split(' ')\n",
        "            assert len(line_split) >= 9\n",
        "            file_name_split = line_split[0].split('-')\n",
        "            file_name_subdir1 = file_name_split[0]\n",
        "            file_name_subdir2 = f'{file_name_split[0]}-{file_name_split[1]}'\n",
        "            file_base_name = line_split[0] + '.png'\n",
        "            file_name = data_dir / 'img' / file_name_subdir1 / file_name_subdir2 / file_base_name\n",
        "            if line_split[0] in bad_samples_reference:\n",
        "                print('Ignoring known broken image:', file_name)\n",
        "                continue\n",
        "            gt_text = ' '.join(line_split[8:])\n",
        "            chars = chars.union(set(list(gt_text)))\n",
        "            self.samples.append(Sample(gt_text, file_name))\n",
        "        split_idx = int(data_split * len(self.samples))\n",
        "        self.train_samples = self.samples[:split_idx]\n",
        "        self.validation_samples = self.samples[split_idx:]\n",
        "        self.train_words = [x.gt_text for x in self.train_samples]\n",
        "        self.validation_words = [x.gt_text for x in self.validation_samples]\n",
        "        self.train_set()\n",
        "        self.char_list = sorted(list(chars))\n",
        "    def train_set(self) -> None:\n",
        "        self.data_augmentation = True\n",
        "        self.curr_idx = 0\n",
        "        random.shuffle(self.train_samples)\n",
        "        self.samples = self.train_samples\n",
        "        self.curr_set = 'train'\n",
        "    def validation_set(self) -> None:\n",
        "        self.data_augmentation = False\n",
        "        self.curr_idx = 0\n",
        "        self.samples = self.validation_samples\n",
        "        self.curr_set = 'val'\n",
        "    def get_iterator_info(self) -> Tuple[int, int]:\n",
        "        if self.curr_set == 'train':\n",
        "            num_batches = int(np.floor(len(self.samples) / self.batch_size))\n",
        "        else:\n",
        "            num_batches = int(np.ceil(len(self.samples) / self.batch_size))\n",
        "        curr_batch = self.curr_idx // self.batch_size + 1\n",
        "        return curr_batch, num_batches\n",
        "    def has_next(self) -> bool:\n",
        "        if self.curr_set == 'train':\n",
        "            return self.curr_idx + self.batch_size <= len(self.samples)\n",
        "        else:\n",
        "            return self.curr_idx < len(self.samples)\n",
        "    def _get_img(self, i: int) -> np.ndarray:\n",
        "        if self.fast:\n",
        "            with self.env.begin() as txn:\n",
        "                basename = Path(self.samples[i].file_path).basename()\n",
        "                data = txn.get(basename.encode(\"ascii\"))\n",
        "                img = pickle.loads(data)\n",
        "        else:\n",
        "            img = cv2.imread(self.samples[i].file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        return img\n",
        "    def get_next(self) -> Batch:\n",
        "        batch_range = range(self.curr_idx, min(self.curr_idx + self.batch_size, len(self.samples)))\n",
        "        imgs = [self._get_img(i) for i in batch_range]\n",
        "        gt_texts = [self.samples[i].gt_text for i in batch_range]\n",
        "        self.curr_idx += self.batch_size\n",
        "        return Batch(imgs, gt_texts, len(imgs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDBogCqs9swr"
      },
      "outputs": [],
      "source": [
        "class Preprocessor:\n",
        "    def __init__(self,\n",
        "                 img_size: Tuple[int, int],\n",
        "                 padding: int = 0,\n",
        "                 dynamic_width: bool = False,\n",
        "                 data_augmentation: bool = False,\n",
        "                 line_mode: bool = False) -> None:\n",
        "        assert not (dynamic_width and data_augmentation)\n",
        "        assert not (padding > 0 and not dynamic_width)\n",
        "        self.img_size = img_size\n",
        "        self.padding = padding\n",
        "        self.dynamic_width = dynamic_width\n",
        "        self.data_augmentation = data_augmentation\n",
        "        self.line_mode = line_mode\n",
        "    @staticmethod\n",
        "    def _truncate_label(text: str, max_text_len: int) -> str:\n",
        "        cost = 0\n",
        "        for i in range(len(text)):\n",
        "            if i != 0 and text[i] == text[i - 1]:\n",
        "                cost += 2\n",
        "            else:\n",
        "                cost += 1\n",
        "            if cost > max_text_len:\n",
        "                return text[:i]\n",
        "        return text\n",
        "    def _simulate_text_line(self, batch: Batch) -> Batch:\n",
        "        default_word_sep = 30\n",
        "        default_num_words = 5\n",
        "        res_imgs = []\n",
        "        res_gt_texts = []\n",
        "        for i in range(batch.batch_size):\n",
        "            num_words = random.randint(1, 8) if self.data_augmentation else default_num_words\n",
        "            curr_gt = ' '.join([batch.gt_texts[(i + j) % batch.batch_size] for j in range(num_words)])\n",
        "            res_gt_texts.append(curr_gt)\n",
        "            sel_imgs = []\n",
        "            word_seps = [0]\n",
        "            h = 0\n",
        "            w = 0\n",
        "            for j in range(num_words):\n",
        "                curr_sel_img = batch.imgs[(i + j) % batch.batch_size]\n",
        "                curr_word_sep = random.randint(20, 50) if self.data_augmentation else default_word_sep\n",
        "                h = max(h, curr_sel_img.shape[0])\n",
        "                w += curr_sel_img.shape[1]\n",
        "                sel_imgs.append(curr_sel_img)\n",
        "                if j + 1 < num_words:\n",
        "                    w += curr_word_sep\n",
        "                    word_seps.append(curr_word_sep)\n",
        "            target = np.ones([h, w], np.uint8) * 255\n",
        "            x = 0\n",
        "            for curr_sel_img, curr_word_sep in zip(sel_imgs, word_seps):\n",
        "                x += curr_word_sep\n",
        "                y = (h - curr_sel_img.shape[0]) // 2\n",
        "                target[y:y + curr_sel_img.shape[0]:, x:x + curr_sel_img.shape[1]] = curr_sel_img\n",
        "                x += curr_sel_img.shape[1]\n",
        "            res_imgs.append(target)\n",
        "        return Batch(res_imgs, res_gt_texts, batch.batch_size)\n",
        "    def process_img(self, img: np.ndarray) -> np.ndarray:\n",
        "        if img is None:\n",
        "            img = np.zeros(self.img_size[::-1])\n",
        "        img = img.astype(np.float)\n",
        "        if self.data_augmentation:\n",
        "            if random.random() < 0.25:\n",
        "                def rand_odd():\n",
        "                    return random.randint(1, 3) * 2 + 1\n",
        "                img = cv2.GaussianBlur(img, (rand_odd(), rand_odd()), 0)\n",
        "            if random.random() < 0.25:\n",
        "                img = cv2.dilate(img, np.ones((3, 3)))\n",
        "            if random.random() < 0.25:\n",
        "                img = cv2.erode(img, np.ones((3, 3)))\n",
        "            wt, ht = self.img_size\n",
        "            h, w = img.shape\n",
        "            f = min(wt / w, ht / h)\n",
        "            fx = f * np.random.uniform(0.75, 1.05)\n",
        "            fy = f * np.random.uniform(0.75, 1.05)\n",
        "            txc = (wt - w * fx) / 2\n",
        "            tyc = (ht - h * fy) / 2\n",
        "            freedom_x = max((wt - fx * w) / 2, 0)\n",
        "            freedom_y = max((ht - fy * h) / 2, 0)\n",
        "            tx = txc + np.random.uniform(-freedom_x, freedom_x)\n",
        "            ty = tyc + np.random.uniform(-freedom_y, freedom_y)\n",
        "            M = np.float32([[fx, 0, tx], [0, fy, ty]])\n",
        "            target = np.ones(self.img_size[::-1]) * 255\n",
        "            img = cv2.warpAffine(img, M, dsize=self.img_size, dst=target, borderMode=cv2.BORDER_TRANSPARENT)\n",
        "            if random.random() < 0.5:\n",
        "                img = img * (0.25 + random.random() * 0.75)\n",
        "            if random.random() < 0.25:\n",
        "                img = np.clip(img + (np.random.random(img.shape) - 0.5) * random.randint(1, 25), 0, 255)\n",
        "            if random.random() < 0.1:\n",
        "                img = 255 - img\n",
        "        else:\n",
        "            if self.dynamic_width:\n",
        "                ht = self.img_size[1]\n",
        "                h, w = img.shape\n",
        "                f = ht / h\n",
        "                wt = int(f * w + self.padding)\n",
        "                wt = wt + (4 - wt) % 4\n",
        "                tx = (wt - w * f) / 2\n",
        "                ty = 0\n",
        "            else:\n",
        "                wt, ht = self.img_size\n",
        "                h, w = img.shape\n",
        "                f = min(wt / w, ht / h)\n",
        "                tx = (wt - w * f) / 2\n",
        "                ty = (ht - h * f) / 2\n",
        "            M = np.float32([[f, 0, tx], [0, f, ty]])\n",
        "            target = np.ones([ht, wt]) * 255\n",
        "            img = cv2.warpAffine(img, M, dsize=(wt, ht), dst=target, borderMode=cv2.BORDER_TRANSPARENT)\n",
        "        img = cv2.transpose(img)\n",
        "        img = img / 255 - 0.5\n",
        "        return img\n",
        "    def process_batch(self, batch: Batch) -> Batch:\n",
        "        if self.line_mode:\n",
        "            batch = self._simulate_text_line(batch)\n",
        "        res_imgs = [self.process_img(img) for img in batch.imgs]\n",
        "        max_text_len = res_imgs[0].shape[0] // 4\n",
        "        res_gt_texts = [self._truncate_label(gt_text, max_text_len) for gt_text in batch.gt_texts]\n",
        "        return Batch(res_imgs, res_gt_texts, batch.batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qolqD_4GDCbD"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    import matplotlib.pyplot as plt\n",
        "    img = cv2.imread('../data/test.png', cv2.IMREAD_GRAYSCALE)\n",
        "    img_aug = Preprocessor((256, 32), data_augmentation=True).process_img(img)\n",
        "    plt.subplot(121)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.subplot(122)\n",
        "    plt.imshow(cv2.transpose(img_aug) + 0.5, cmap='gray', vmin=0, vmax=1)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2lF2rHPX7IX"
      },
      "outputs": [],
      "source": [
        "tf.compat.v1.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEdKow2mYEF2"
      },
      "outputs": [],
      "source": [
        "class DecoderType:\n",
        "    BestPath = 0\n",
        "    BeamSearch = 1\n",
        "    WordBeamSearch = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8fxi0O-YJrG"
      },
      "outputs": [],
      "source": [
        "class Model:\n",
        "    def __init__(self,\n",
        "                 char_list: List[str],\n",
        "                 decoder_type: str = DecoderType.BestPath,\n",
        "                 must_restore: bool = False,\n",
        "                 dump: bool = False) -> None:\n",
        "        self.dump = dump\n",
        "        self.char_list = char_list\n",
        "        self.decoder_type = decoder_type\n",
        "        self.must_restore = must_restore\n",
        "        self.snap_ID = 0\n",
        "        self.is_train = tf.compat.v1.placeholder(tf.bool, name='is_train')\n",
        "        self.input_imgs = tf.compat.v1.placeholder(tf.float32, shape=(None, None, None))\n",
        "        self.setup_cnn()\n",
        "        self.setup_rnn()\n",
        "        self.setup_ctc()\n",
        "        self.batches_trained = 0\n",
        "        self.update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)\n",
        "        with tf.control_dependencies(self.update_ops):\n",
        "            self.optimizer = tf.compat.v1.train.AdamOptimizer().minimize(self.loss)\n",
        "        self.sess, self.saver = self.setup_tf()\n",
        "    def setup_cnn(self) -> None:\n",
        "        cnn_in4d = tf.expand_dims(input=self.input_imgs, axis=3)\n",
        "        kernel_vals = [5, 5, 3, 3, 3]\n",
        "        feature_vals = [1, 32, 64, 128, 128, 256]\n",
        "        stride_vals = pool_vals = [(2, 2), (2, 2), (1, 2), (1, 2), (1, 2)]\n",
        "        num_layers = len(stride_vals)\n",
        "        pool = cnn_in4d\n",
        "        for i in range(num_layers):\n",
        "            kernel = tf.Variable(\n",
        "                tf.random.truncated_normal([kernel_vals[i], kernel_vals[i], feature_vals[i], feature_vals[i + 1]],\n",
        "                                           stddev=0.1))\n",
        "            conv = tf.nn.conv2d(input=pool, filters=kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
        "            conv_norm = tf.compat.v1.layers.batch_normalization(conv, training=self.is_train)\n",
        "            relu = tf.nn.relu(conv_norm)\n",
        "            pool = tf.nn.max_pool2d(input=relu, ksize=(1, pool_vals[i][0], pool_vals[i][1], 1),\n",
        "                                    strides=(1, stride_vals[i][0], stride_vals[i][1], 1), padding='VALID')\n",
        "        self.cnn_out_4d = pool\n",
        "    def setup_rnn(self) -> None:\n",
        "        rnn_in3d = tf.squeeze(self.cnn_out_4d, axis=[2])\n",
        "        num_hidden = 256\n",
        "        cells = [tf.compat.v1.nn.rnn_cell.LSTMCell(num_units=num_hidden, state_is_tuple=True) for _ in\n",
        "                 range(2)]\n",
        "        stacked = tf.compat.v1.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)\n",
        "        (fw, bw), _ = tf.compat.v1.nn.bidirectional_dynamic_rnn(cell_fw=stacked, cell_bw=stacked, inputs=rnn_in3d,\n",
        "                                                                dtype=rnn_in3d.dtype)\n",
        "        concat = tf.expand_dims(tf.concat([fw, bw], 2), 2)\n",
        "        kernel = tf.Variable(tf.random.truncated_normal([1, 1, num_hidden * 2, len(self.char_list) + 1], stddev=0.1))\n",
        "        self.rnn_out_3d = tf.squeeze(tf.nn.atrous_conv2d(value=concat, filters=kernel, rate=1, padding='SAME'),\n",
        "                                     axis=[2])\n",
        "    def setup_ctc(self) -> None:\n",
        "        self.ctc_in_3d_tbc = tf.transpose(a=self.rnn_out_3d, perm=[1, 0, 2])\n",
        "        self.gt_texts = tf.SparseTensor(tf.compat.v1.placeholder(tf.int64, shape=[None, 2]),\n",
        "                                        tf.compat.v1.placeholder(tf.int32, [None]),\n",
        "                                        tf.compat.v1.placeholder(tf.int64, [2]))\n",
        "        self.seq_len = tf.compat.v1.placeholder(tf.int32, [None])\n",
        "        self.loss = tf.reduce_mean(\n",
        "            input_tensor=tf.compat.v1.nn.ctc_loss(labels=self.gt_texts, inputs=self.ctc_in_3d_tbc,\n",
        "                                                  sequence_length=self.seq_len,\n",
        "                                                  ctc_merge_repeated=True))\n",
        "        self.saved_ctc_input = tf.compat.v1.placeholder(tf.float32,\n",
        "                                                        shape=[None, None, len(self.char_list) + 1])\n",
        "        self.loss_per_element = tf.compat.v1.nn.ctc_loss(labels=self.gt_texts, inputs=self.saved_ctc_input,\n",
        "                                                         sequence_length=self.seq_len, ctc_merge_repeated=True)\n",
        "\n",
        "        if self.decoder_type == DecoderType.BestPath:\n",
        "            self.decoder = tf.nn.ctc_greedy_decoder(inputs=self.ctc_in_3d_tbc, sequence_length=self.seq_len)\n",
        "        elif self.decoder_type == DecoderType.BeamSearch:\n",
        "            self.decoder = tf.nn.ctc_beam_search_decoder(inputs=self.ctc_in_3d_tbc, sequence_length=self.seq_len,\n",
        "                                                         beam_width=50)\n",
        "        elif self.decoder_type == DecoderType.WordBeamSearch:\n",
        "            chars = ''.join(self.char_list)\n",
        "            word_chars = open('../model/wordCharList.txt').read().splitlines()[0]\n",
        "            corpus = open('../data/corpus.txt').read()\n",
        "            from word_beam_search import WordBeamSearch\n",
        "            self.decoder = WordBeamSearch(50, 'Words', 0.0, corpus.encode('utf8'), chars.encode('utf8'),\n",
        "                                          word_chars.encode('utf8'))\n",
        "            self.wbs_input = tf.nn.softmax(self.ctc_in_3d_tbc, axis=2)\n",
        "    def setup_tf(self) -> Tuple[tf.compat.v1.Session, tf.compat.v1.train.Saver]:\n",
        "        print('Python: ' + sys.version)\n",
        "        print('Tensorflow: ' + tf.__version__)\n",
        "        sess = tf.compat.v1.Session()\n",
        "        saver = tf.compat.v1.train.Saver(max_to_keep=1)\n",
        "        model_dir = '../model/'\n",
        "        latest_snapshot = tf.train.latest_checkpoint(model_dir)\n",
        "        if self.must_restore and not latest_snapshot:\n",
        "            raise Exception('No saved model found in: ' + model_dir)\n",
        "        if latest_snapshot:\n",
        "            print('Init with stored values from ' + latest_snapshot)\n",
        "            saver.restore(sess, latest_snapshot)\n",
        "        else:\n",
        "            print('Init with new values')\n",
        "            sess.run(tf.compat.v1.global_variables_initializer())\n",
        "        return sess, saver\n",
        "    def to_sparse(self, texts: List[str]) -> Tuple[List[List[int]], List[int], List[int]]:\n",
        "        indices = []\n",
        "        values = []\n",
        "        shape = [len(texts), 0]\n",
        "        for batchElement, text in enumerate(texts):\n",
        "            label_str = [self.char_list.index(c) for c in text]\n",
        "            if len(label_str) > shape[1]:\n",
        "                shape[1] = len(label_str)\n",
        "            for i, label in enumerate(label_str):\n",
        "                indices.append([batchElement, i])\n",
        "                values.append(label)\n",
        "        return indices, values, shape\n",
        "    def decoder_output_to_text(self, ctc_output: tuple, batch_size: int) -> List[str]:\n",
        "        if self.decoder_type == DecoderType.WordBeamSearch:\n",
        "            label_strs = ctc_output\n",
        "        else:\n",
        "            decoded = ctc_output[0][0]\n",
        "            label_strs = [[] for _ in range(batch_size)]\n",
        "            for (idx, idx2d) in enumerate(decoded.indices):\n",
        "                label = decoded.values[idx]\n",
        "                batch_element = idx2d[0]\n",
        "                label_strs[batch_element].append(label)\n",
        "        return [''.join([self.char_list[c] for c in labelStr]) for labelStr in label_strs]\n",
        "    def train_batch(self, batch: Batch) -> float:\n",
        "        num_batch_elements = len(batch.imgs)\n",
        "        max_text_len = batch.imgs[0].shape[0] // 4\n",
        "        sparse = self.to_sparse(batch.gt_texts)\n",
        "        eval_list = [self.optimizer, self.loss]\n",
        "        feed_dict = {self.input_imgs: batch.imgs, self.gt_texts: sparse,\n",
        "                     self.seq_len: [max_text_len] * num_batch_elements, self.is_train: True}\n",
        "        _, loss_val = self.sess.run(eval_list, feed_dict)\n",
        "        self.batches_trained += 1\n",
        "        return loss_val\n",
        "    @staticmethod\n",
        "    def dump_nn_output(rnn_output: np.ndarray) -> None:\n",
        "        dump_dir = '../dump/'\n",
        "        if not os.path.isdir(dump_dir):\n",
        "            os.mkdir(dump_dir)\n",
        "        max_t, max_b, max_c = rnn_output.shape\n",
        "        for b in range(max_b):\n",
        "            csv = ''\n",
        "            for t in range(max_t):\n",
        "                for c in range(max_c):\n",
        "                    csv += str(rnn_output[t, b, c]) + ';'\n",
        "                csv += '\\n'\n",
        "            fn = dump_dir + 'rnnOutput_' + str(b) + '.csv'\n",
        "            print('Write dump of NN to file: ' + fn)\n",
        "            with open(fn, 'w') as f:\n",
        "                f.write(csv)\n",
        "    def infer_batch(self, batch: Batch, calc_probability: bool = False, probability_of_gt: bool = False):\n",
        "        num_batch_elements = len(batch.imgs)\n",
        "        eval_list = []\n",
        "\n",
        "        if self.decoder_type == DecoderType.WordBeamSearch:\n",
        "            eval_list.append(self.wbs_input)\n",
        "        else:\n",
        "            eval_list.append(self.decoder)\n",
        "        if self.dump or calc_probability:\n",
        "            eval_list.append(self.ctc_in_3d_tbc)\n",
        "        max_text_len = batch.imgs[0].shape[0] // 4\n",
        "        feed_dict = {self.input_imgs: batch.imgs, self.seq_len: [max_text_len] * num_batch_elements,\n",
        "                     self.is_train: False}\n",
        "        eval_res = self.sess.run(eval_list, feed_dict)\n",
        "        if self.decoder_type != DecoderType.WordBeamSearch:\n",
        "            decoded = eval_res[0]\n",
        "        else:\n",
        "            decoded = self.decoder.compute(eval_res[0])\n",
        "        texts = self.decoder_output_to_text(decoded, num_batch_elements)\n",
        "        probs = None\n",
        "        if calc_probability:\n",
        "            sparse = self.to_sparse(batch.gt_texts) if probability_of_gt else self.to_sparse(texts)\n",
        "            ctc_input = eval_res[1]\n",
        "            eval_list = self.loss_per_element\n",
        "            feed_dict = {self.saved_ctc_input: ctc_input, self.gt_texts: sparse,\n",
        "                         self.seq_len: [max_text_len] * num_batch_elements, self.is_train: False}\n",
        "            loss_vals = self.sess.run(eval_list, feed_dict)\n",
        "            probs = np.exp(-loss_vals)\n",
        "        if self.dump:\n",
        "            self.dump_nn_output(eval_res[1])\n",
        "        return texts, probs\n",
        "    def save(self) -> None:\n",
        "        self.snap_ID += 1\n",
        "        self.saver.save(self.sess, '../model/snapshot', global_step=self.snap_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssSbdE8-aC_u"
      },
      "outputs": [],
      "source": [
        "class FilePaths:\n",
        "    fn_char_list = '/content/charList.txt'\n",
        "    fn_summary = '/content/summary.json'\n",
        "    fn_corpus = '/content/corpus.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cpd1qnAtaXJ8"
      },
      "outputs": [],
      "source": [
        "def get_img_height() -> int:\n",
        "    return 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxQYw_A_acab"
      },
      "outputs": [],
      "source": [
        "def get_img_size(line_mode: bool = False) -> Tuple[int, int]:\n",
        "    if line_mode:\n",
        "        return 256, get_img_height()\n",
        "    return 128, get_img_height()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbxxv6yGahW_"
      },
      "outputs": [],
      "source": [
        "def write_summary(average_train_loss: List[float], char_error_rates: List[float], word_accuracies: List[float]) -> None:\n",
        "    with open(FilePaths.fn_summary, 'w') as f:\n",
        "        json.dump({'averageTrainLoss': average_train_loss, 'charErrorRates': char_error_rates, 'wordAccuracies': word_accuracies}, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsKriNN9amSf"
      },
      "outputs": [],
      "source": [
        "def char_list_from_file() -> List[str]:\n",
        "    with open(FilePaths.fn_char_list) as f:\n",
        "        return list(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCD7fHnyapev"
      },
      "outputs": [],
      "source": [
        "def train(model: Model,\n",
        "          loader: DataLoaderIAM,\n",
        "          line_mode: bool,\n",
        "          early_stopping: int = 25) -> None:\n",
        "    epoch = 0\n",
        "    summary_char_error_rates = []\n",
        "    summary_word_accuracies = []\n",
        "    train_loss_in_epoch = []\n",
        "    average_train_loss = []\n",
        "    preprocessor = Preprocessor(get_img_size(line_mode), data_augmentation=True, line_mode=line_mode)\n",
        "    best_char_error_rate = float('inf')\n",
        "    while True:\n",
        "        epoch += 1\n",
        "        print('Epoch:', epoch)\n",
        "        print('Train NN')\n",
        "        loader.train_set()\n",
        "        while loader.has_next():\n",
        "            iter_info = loader.get_iterator_info()\n",
        "            batch = loader.get_next()\n",
        "            batch = preprocessor.process_batch(batch)\n",
        "            loss = model.train_batch(batch)\n",
        "            print(f'Epoch: {epoch} Batch: {iter_info[0]}/{iter_info[1]} Loss: {loss}')\n",
        "            train_loss_in_epoch.append(loss)\n",
        "        char_error_rate, word_accuracy = validate(model, loader, line_mode)\n",
        "        summary_char_error_rates.append(char_error_rate)\n",
        "        summary_word_accuracies.append(word_accuracy)\n",
        "        average_train_loss.append((sum(train_loss_in_epoch)) / len(train_loss_in_epoch))\n",
        "        write_summary(average_train_loss, summary_char_error_rates, summary_word_accuracies)\n",
        "        train_loss_in_epoch = []\n",
        "        if char_error_rate < best_char_error_rate:\n",
        "            print('Character error rate improved, save model')\n",
        "            best_char_error_rate = char_error_rate\n",
        "            no_improvement_since = 0\n",
        "            model.save()\n",
        "        else:\n",
        "            print(f'Character error rate not improved, best so far: {best_char_error_rate * 100.0}%')\n",
        "            no_improvement_since += 1\n",
        "        if no_improvement_since >= early_stopping:\n",
        "            print(f'No more improvement for {early_stopping} epochs. Training stopped.')\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntao0FPhbOFF"
      },
      "outputs": [],
      "source": [
        "def validate(model: Model, loader: DataLoaderIAM, line_mode: bool) -> Tuple[float, float]:\n",
        "    print('Validate NN')\n",
        "    loader.validation_set()\n",
        "    preprocessor = Preprocessor(get_img_size(line_mode), line_mode=line_mode)\n",
        "    num_char_err = 0\n",
        "    num_char_total = 0\n",
        "    num_word_ok = 0\n",
        "    num_word_total = 0\n",
        "    while loader.has_next():\n",
        "        iter_info = loader.get_iterator_info()\n",
        "        print(f'Batch: {iter_info[0]} / {iter_info[1]}')\n",
        "        batch = loader.get_next()\n",
        "        batch = preprocessor.process_batch(batch)\n",
        "        recognized, _ = model.infer_batch(batch)\n",
        "        print('Ground truth -> Recognized')\n",
        "        for i in range(len(recognized)):\n",
        "            num_word_ok += 1 if batch.gt_texts[i] == recognized[i] else 0\n",
        "            num_word_total += 1\n",
        "            dist = editdistance.eval(recognized[i], batch.gt_texts[i])\n",
        "            num_char_err += dist\n",
        "            num_char_total += len(batch.gt_texts[i])\n",
        "            print('[OK]' if dist == 0 else '[ERR:%d]' % dist, '\"' + batch.gt_texts[i] + '\"', '->',\n",
        "                  '\"' + recognized[i] + '\"')\n",
        "    char_error_rate = num_char_err / num_char_total\n",
        "    word_accuracy = num_word_ok / num_word_total\n",
        "    print(f'Character error rate: {char_error_rate * 100.0}%. Word accuracy: {word_accuracy * 100.0}%.')\n",
        "    return char_error_rate, word_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f92-hUGWbaHX"
      },
      "outputs": [],
      "source": [
        "def infer(model: Model, fn_img: Path) -> None:\n",
        "    img = cv2.imread(fn_img, cv2.IMREAD_GRAYSCALE)\n",
        "    assert img is not None\n",
        "    preprocessor = Preprocessor(get_img_size(), dynamic_width=True, padding=16)\n",
        "    img = preprocessor.process_img(img)\n",
        "    batch = Batch([img], None, 1)\n",
        "    recognized, probability = model.infer_batch(batch, True)\n",
        "    print(f'Recognized: \"{recognized[0]}\"')\n",
        "    print(f'Probability: {probability[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTV1wNk1bhDv"
      },
      "outputs": [],
      "source": [
        "def parse_args() -> argparse.Namespace:\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--mode', choices=['train', 'validate', 'infer'], default='infer')\n",
        "    parser.add_argument('--decoder', choices=['bestpath', 'beamsearch', 'wordbeamsearch'], default='bestpath')\n",
        "    parser.add_argument('--batch_size', help='Batch size.', type=int, default=100)\n",
        "    parser.add_argument('--data_dir', help='Directory containing IAM dataset.', type=Path, required=False)\n",
        "    parser.add_argument('--fast', help='Load samples from LMDB.', action='store_true')\n",
        "    parser.add_argument('--line_mode', help='Train to read text lines instead of single words.', action='store_true')\n",
        "    parser.add_argument('--img_file', help='Image used for inference.', type=Path, default='../data/word.png')\n",
        "    parser.add_argument('--early_stopping', help='Early stopping epochs.', type=int, default=25)\n",
        "    parser.add_argument('--dump', help='Dump output of NN to CSV file(s).', action='store_true')\n",
        "    return parser.parse_args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80TaTlNI6aVl"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    args = parse_args()\n",
        "    decoder_mapping = {'bestpath': DecoderType.BestPath,\n",
        "                       'beamsearch': DecoderType.BeamSearch,\n",
        "                       'wordbeamsearch': DecoderType.WordBeamSearch}\n",
        "    decoder_type = decoder_mapping[args.decoder]\n",
        "    if args.mode == 'train':\n",
        "        loader = DataLoaderIAM(args.data_dir, args.batch_size, fast=args.fast)\n",
        "        char_list = loader.char_list\n",
        "        if args.line_mode and ' ' not in char_list:\n",
        "            char_list = [' '] + char_list\n",
        "        with open(FilePaths.fn_char_list, 'w') as f:\n",
        "            f.write(''.join(char_list))\n",
        "        with open(FilePaths.fn_corpus, 'w') as f:\n",
        "            f.write(' '.join(loader.train_words + loader.validation_words))\n",
        "        model = Model(char_list, decoder_type)\n",
        "        train(model, loader, line_mode=args.line_mode, early_stopping=args.early_stopping)\n",
        "    elif args.mode == 'validate':\n",
        "        loader = DataLoaderIAM(args.data_dir, args.batch_size, fast=args.fast)\n",
        "        model = Model(char_list_from_file(), decoder_type, must_restore=True)\n",
        "        validate(model, loader, args.line_mode)\n",
        "    elif args.mode == 'infer':\n",
        "        model = Model(char_list_from_file(), decoder_type, must_restore=True, dump=args.dump)\n",
        "        infer(model, args.img_file)\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}